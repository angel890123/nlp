{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit (windows store)"
  },
  "interpreter": {
   "hash": "51dc9676033afd2a491cf59d7b1c70c3cea9273ba80257c1b4703051bab2b9dc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import jieba\r\n",
    "import re\r\n",
    "import jieba.analyse\r\n",
    "import math\r\n",
    "# importing pandas library\r\n",
    "import pandas as pd\r\n",
    "# importing matplotlib library\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from collections import Counter\r\n",
    "# encoding=utf-8\r\n",
    "def scan():\r\n",
    "    r = '[’!\"#$%&\\'()*+,-./:;<=>[email protected][\\\\]^_`{|}~]+'\r\n",
    "    text = open('hw1-dataset.txt','r',encoding = 'utf-8')\r\n",
    "    word=\" \"\r\n",
    "    for line in text:\r\n",
    "        line = line.strip('\\n')\r\n",
    "        line = re.sub(r, ' ', line)\r\n",
    "        seg_list = jieba.cut(line, cut_all=False)\r\n",
    "        word+=(\" \".join(seg_list))\r\n",
    "    text.close()\r\n",
    "    words=word.split()\r\n",
    "    return words    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def TF_IDF():\r\n",
    "    index=[]\r\n",
    "    TF_IDF=[]\r\n",
    "    i=0\r\n",
    "    text = open('hw1-dataset.txt','r',encoding = 'utf-8').read()\r\n",
    "    tags = jieba.analyse.extract_tags(text, topK=100, withWeight=True)\r\n",
    "    print('前100個TF_IDF字詞')\r\n",
    "    for tag in tags:\r\n",
    "        i=i+1\r\n",
    "        print(i,'word:', tag[0], 'tf-idf:', tag[1])\r\n",
    "        index.append(i)\r\n",
    "        TF_IDF.append(tag[1])\r\n",
    "    df = pd.DataFrame({'word':index,'TF_IDF':TF_IDF})\r\n",
    "    df.plot(x=\"word\", y=\"TF_IDF\", kind=\"bar\",figsize=(30,15))\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def frequency(words):\r\n",
    "    freq=[]\r\n",
    "    index=[]\r\n",
    "    i=0\r\n",
    "    num=Counter()\r\n",
    "    print('前100個高頻字詞')\r\n",
    "    for x in words:\r\n",
    "        if len(x)>1 and x!='\\r\\n\\t':\r\n",
    "            num[x]+=1\r\n",
    "    for tag in num.most_common(100):\r\n",
    "        i=i+1\r\n",
    "        print(i,'word:', tag[0], 'frequency:', tag[1])\r\n",
    "        index.append(i)\r\n",
    "        freq.append(tag[1])\r\n",
    "    df = pd.DataFrame({'word':index,'frequency':freq})\r\n",
    "    df.plot(x=\"word\", y=\"frequency\", kind=\"bar\",figsize=(30,15))\r\n",
    "    plt.show()\r\n",
    "    return freq"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Words = scan()\r\n",
    "TF_IDF()\r\n",
    "freq=frequency(Words)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}